{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install All necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /opt/anaconda3/lib/python3.11/site-packages (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/anaconda3/lib/python3.11/site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from gensim) (1.11.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/anaconda3/lib/python3.11/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: FuzzyTM>=0.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from gensim) (2.0.5)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (from FuzzyTM>=0.4.0->gensim) (2.1.4)\n",
      "Requirement already satisfied: pyfume in /opt/anaconda3/lib/python3.11/site-packages (from FuzzyTM>=0.4.0->gensim) (0.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2023.3)\n",
      "Requirement already satisfied: simpful in /opt/anaconda3/lib/python3.11/site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (2.12.0)\n",
      "Requirement already satisfied: fst-pso in /opt/anaconda3/lib/python3.11/site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (1.8.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.11/site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (4.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Requirement already satisfied: miniful in /opt/anaconda3/lib/python3.11/site-packages (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim) (0.0.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:48:05.466806Z",
     "start_time": "2024-07-10T19:48:02.416554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/anaconda3/lib/python3.11/site-packages (24.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:48:11.295166Z",
     "start_time": "2024-07-10T19:48:10.793631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy, Scipy, Gensim, Matplotlib, and Scikit-learn imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import triu  # Correct import for triu\n",
    "from scipy.linalg import lu\n",
    "from gensim.models import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "print(\"Numpy, Scipy, Gensim, Matplotlib, and Scikit-learn imported successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:48:12.290476Z",
     "start_time": "2024-07-10T19:48:11.305670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/harshikhaagarwal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/harshikhaagarwal/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/harshikhaagarwal/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "print(\"All imports successful.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up Directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:48:20.847752Z",
     "start_time": "2024-07-10T19:48:20.632526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows excluding the column names is: 5000\n",
      "Index(['pgpub_id', 'application_id', 'filing_date', 'patent_type',\n",
      "       'filing_type', 'published_date', 'wipo_kind', 'series_code',\n",
      "       'application_title', 'application_abstract', 'rule_47_flag', 'filename',\n",
      "       'rel_app_text', 'patent_id', 'current_pgpub_id_flag',\n",
      "       'current_patent_id_flag', 'uspc_sequence', 'uspc_mainclass_id',\n",
      "       'uspc_mainclass_title', 'uspc_subclass_id', 'uspc_subclass_title',\n",
      "       'published_or_filed_date', 'pct_371_date', 'pct_102_date',\n",
      "       'filed_country', 'application_kind', 'pct_doc_number', 'pct_doc_type',\n",
      "       'wipo_field_sequence', 'wipo_field_id', 'wipo_sector_title',\n",
      "       'wipo_field_title', 'priority_claim_sequence', 'priority_claim_kind',\n",
      "       'foreign_application_id', 'foreign_filing_date',\n",
      "       'foreign_country_filed', 'cpc_sequence', 'cpc_section', 'cpc_class',\n",
      "       'cpc_subclass', 'cpc_group', 'cpc_type', 'cpc_version_indicator',\n",
      "       'cpc_subclass_title', 'cpc_group_title', 'cpc_class_title'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Define the file path\n",
    "file_path = 'final_sample.csv'\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "num_rows = df.shape[0]\n",
    "\n",
    "print(f'The number of rows excluding the column names is: {num_rows}')\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:48:29.136010Z",
     "start_time": "2024-07-10T19:48:29.108944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All pgpub_id values are unique.\n"
     ]
    }
   ],
   "source": [
    "pgpub_id_unique = df['pgpub_id'].is_unique\n",
    "\n",
    "# Print the result\n",
    "if pgpub_id_unique:\n",
    "    print(\"All pgpub_id values are unique.\")\n",
    "else:\n",
    "    print(\"There are duplicate pgpub_id values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:48:31.284678Z",
     "start_time": "2024-07-10T19:48:31.276550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    0\n",
      "2    1\n",
      "3    0\n",
      "4    1\n",
      "Name: approval_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['approval_status'] = np.where(df['patent_id'].isnull(), 0, 1)\n",
    "print(df['approval_status'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and Pre-Process the Text Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:48:58.406440Z",
     "start_time": "2024-07-10T19:48:36.680079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words in the entire dataset: 8829\n",
      "Average number of words in patent application abstract: 61.994\n",
      "Average unique words per patent application abstract: 1.7658\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove punctuation and convert to lowercase\n",
    "    tokens = [word.lower() for word in tokens if word.isalpha()]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    \n",
    "    # Lemmatization\n",
    "    #lemmatizer = WordNetLemmatizer()\n",
    "    #tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    # Join tokens back into a single string\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    \n",
    "    return preprocessed_text\n",
    "\n",
    "# Apply preprocessing to application_abstract column\n",
    "df['application_abstract'] = df['application_abstract'].apply(preprocess_text)\n",
    "\n",
    "# Apply preprocessing to rel_app_text column\n",
    "df['rel_app_text'] = df['rel_app_text'].apply(preprocess_text)\n",
    "\n",
    "# Calculate total number of unique words in the entire dataset\n",
    "total_unique_words = len(set(' '.join(df['application_abstract']).split()))\n",
    "\n",
    "# Calculate average number of unique words per patent application\n",
    "average_unique_words_per_application = total_unique_words / len(df)\n",
    "\n",
    "# Tokenize each abstract and count the number of words for each patent application\n",
    "df['word_count'] = df['application_abstract'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Calculate average number of words for every patent application\n",
    "average_words_per_application = df['word_count'].mean()\n",
    "\n",
    "print(\"Total unique words in the entire dataset:\", total_unique_words)\n",
    "print(\"Average number of words in patent application abstract:\", average_words_per_application)\n",
    "print(\"Average unique words per patent application abstract:\", average_unique_words_per_application)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:49:18.604474Z",
     "start_time": "2024-07-10T19:49:18.572975Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting the data into features (X) and target (y)\n",
    "X = df.drop(['approval_status'], axis=1)  \n",
    "y = df['approval_status'] \n",
    "\n",
    "# Performing a universal split on the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Upsample minority class\n",
    "X_minority_upsampled, y_minority_upsampled = resample(X_train[y_train == 0],  # Selecting minority class samples\n",
    "                                                      y_train[y_train == 0],  # Selecting corresponding labels\n",
    "                                                      replace=True,           # Sampling with replacement\n",
    "                                                      n_samples=sum(y_train == 1),  # Number of samples from majority class\n",
    "                                                      random_state=25)        # Set random state for reproducibility\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "X_train_upsampled = pd.concat([X_train[y_train == 1], X_minority_upsampled])\n",
    "y_train_upsampled = pd.concat([y_train[y_train == 1], y_minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_upsampled\n",
    "y_train = y_train_upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Line Model: BOW and TFIDF Vectorized Text Features and Cosine-Similarity Similarity Score with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Unified Dictionary for Vector Representation of Text Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words Vectorization Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:52:49.283813Z",
     "start_time": "2024-07-10T19:52:48.877439Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine the abstract and related application text for vocabulary fitting\n",
    "combined_text = X_train['application_abstract'] + ' ' + X_train['rel_app_text']\n",
    "   \n",
    "# Fit the vectorizer on the combined text\n",
    "vectorizer0 = CountVectorizer()\n",
    "    \n",
    "# Step 1: Bag of Words Vectorization\n",
    "X_train_abstract_bow = vectorizer0.fit_transform(X_train['application_abstract'])\n",
    "X_train_rel_app_text_bow = vectorizer0.transform(X_train['rel_app_text'])\n",
    "X_test_abstract_bow = vectorizer0.transform(X_test['application_abstract'])\n",
    "X_test_rel_app_text_bow = vectorizer0.transform(X_test['rel_app_text'])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T20:11:53.597841Z",
     "start_time": "2024-07-10T20:11:47.603612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1253    0.033113\n",
      "3725    0.000000\n",
      "116     0.000000\n",
      "1199    0.039757\n",
      "1523    0.000000\n",
      "Name: cosine_similarity_bow, dtype: float64\n",
      "3431    0.104524\n",
      "2042    0.000000\n",
      "79      0.000000\n",
      "4663    0.101710\n",
      "3640    0.751960\n",
      "Name: cosine_similarity_bow, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Step 2: Calculate Cosine Similarity\n",
    "cosine_similarity_train_bow = [cosine_similarity(X_train_abstract_bow[i], X_train_rel_app_text_bow[i])[0, 0] for i in range(X_train_abstract_bow.shape[0])]\n",
    "cosine_similarity_test_bow = [cosine_similarity(X_test_abstract_bow[i], X_test_rel_app_text_bow[i])[0, 0] for i in range(X_test_abstract_bow.shape[0])]\n",
    "\n",
    "# Add cosine similarity to the dataframes\n",
    "X_train['cosine_similarity_bow'] = cosine_similarity_train_bow\n",
    "X_test['cosine_similarity_bow'] = cosine_similarity_test_bow\n",
    "\n",
    "print(X_train['cosine_similarity_bow'].head())\n",
    "print(X_test['cosine_similarity_bow'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T20:12:02.828226Z",
     "start_time": "2024-07-10T20:12:02.798475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1253    0.033125\n",
      "3725    0.000000\n",
      "116     0.000000\n",
      "1199    0.039778\n",
      "1523    0.000000\n",
      "Name: fisher_cosine_similarity_bow, dtype: float64\n",
      "3431    0.104907\n",
      "2042    0.000000\n",
      "79      0.000000\n",
      "4663    0.102062\n",
      "3640    0.977450\n",
      "Name: fisher_cosine_similarity_bow, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "  # Apply Fisher transformation\n",
    "def fisher_transform(cosine_similarities_bow):\n",
    "    return [0.5 * np.log((1 + sim) / (1 - sim)) for sim in cosine_similarities_bow]\n",
    "\n",
    "fisher_cosine_similarity_train_bow = fisher_transform(cosine_similarity_train_bow)\n",
    "fisher_cosine_similarity_test_bow = fisher_transform(cosine_similarity_test_bow)\n",
    "\n",
    "# Add Fisher-transformed cosine similarity to the dataframes\n",
    "X_train['fisher_cosine_similarity_bow'] = fisher_cosine_similarity_train_bow\n",
    "X_test['fisher_cosine_similarity_bow'] = fisher_cosine_similarity_test_bow\n",
    "\n",
    "print(X_train['fisher_cosine_similarity_bow'].head())\n",
    "print(X_test['fisher_cosine_similarity_bow'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF Vector Representation Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T20:12:16.163744Z",
     "start_time": "2024-07-10T20:12:12.828254Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine the abstract and related application text for vocabulary fitting\n",
    "combined_text = X_train['application_abstract'] + ' ' + X_train['rel_app_text']\n",
    "\n",
    "# Fit the vectorizer on the combined text\n",
    "vectorizer1 = TfidfVectorizer(ngram_range=(1, 3), max_features=10000)\n",
    "vectorizer1.fit(combined_text)\n",
    "\n",
    "# Transform the abstract and related application text separately using the fitted vectorizer\n",
    "X_train_abstract_tfidf = vectorizer1.transform(X_train['application_abstract'])\n",
    "X_test_abstract_tfidf = vectorizer1.transform(X_test['application_abstract'])\n",
    "X_train_rel_app_text_tfidf = vectorizer1.transform(X_train['rel_app_text'])\n",
    "X_test_rel_app_text_tfidf = vectorizer1.transform(X_test['rel_app_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Line Model: TFIDF Vectorized Text Features and Cosine-Similarity Similarity Score with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T20:12:30.369681Z",
     "start_time": "2024-07-10T20:12:24.835265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1253    0.006685\n",
      "3725    0.000000\n",
      "116     0.000000\n",
      "1199    0.003859\n",
      "1523    0.000000\n",
      "Name: cosine_similarity_tfidf, dtype: float64\n",
      "3431    0.005460\n",
      "2042    0.000000\n",
      "79      0.000000\n",
      "4663    0.129988\n",
      "3640    0.708633\n",
      "Name: cosine_similarity_tfidf, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity for training data\n",
    "cosine_similarity_train_tfidf = [cosine_similarity(X_train_abstract_tfidf[i], X_train_rel_app_text_tfidf[i])[0, 0] for i in range(X_train_abstract_tfidf.shape[0])]\n",
    "\n",
    "# Calculate cosine similarity for test data\n",
    "cosine_similarity_test_tfidf = [cosine_similarity(X_test_abstract_tfidf[i], X_test_rel_app_text_tfidf[i])[0, 0] for i in range(X_test_abstract_tfidf.shape[0])]\n",
    "\n",
    "# Add cosine similarity to the dataframes\n",
    "X_train['cosine_similarity_tfidf'] = cosine_similarity_train_tfidf\n",
    "X_test['cosine_similarity_tfidf'] = cosine_similarity_test_tfidf\n",
    "\n",
    "print(X_train['cosine_similarity_tfidf'].head())\n",
    "print(X_test['cosine_similarity_tfidf'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T20:12:32.806400Z",
     "start_time": "2024-07-10T20:12:32.784176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1253    0.006685\n",
      "3725    0.000000\n",
      "116     0.000000\n",
      "1199    0.003859\n",
      "1523    0.000000\n",
      "Name: fisher_cosine_similarity_tfidf, dtype: float64\n",
      "3431    0.005460\n",
      "2042    0.000000\n",
      "79      0.000000\n",
      "4663    0.130728\n",
      "3640    0.884433\n",
      "Name: fisher_cosine_similarity_tfidf, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Apply Fisher transformation to cosine similarities\n",
    "def fisher_transform(cosine_similarities_tfidf):\n",
    "    return [0.5 * np.log((1 + sim) / (1 - sim)) for sim in cosine_similarities_tfidf]\n",
    "\n",
    "fisher_cosine_similarity_train_tfidf = fisher_transform(cosine_similarity_train_tfidf)\n",
    "fisher_cosine_similarity_test_tfidf= fisher_transform(cosine_similarity_test_tfidf)\n",
    "\n",
    "# Add Fisher-transformed cosine similarity to the dataframes\n",
    "X_train['fisher_cosine_similarity_tfidf'] = fisher_cosine_similarity_train_tfidf\n",
    "X_test['fisher_cosine_similarity_tfidf'] = fisher_cosine_similarity_test_tfidf\n",
    "\n",
    "print(X_train['fisher_cosine_similarity_tfidf'].head())\n",
    "print(X_test['fisher_cosine_similarity_tfidf'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Modelling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T20:14:51.382519Z",
     "start_time": "2024-07-10T20:14:38.177765Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model 0: BOW Abstract as the only feature\n",
    "X_train0 = X_train_abstract_bow.toarray()\n",
    "X_test0 = X_test_abstract_bow.toarray()\n",
    "\n",
    "# Model 1: Combine BOW features from Abstract and Related Application Text\n",
    "X_train1 = np.hstack((X_train_abstract_bow.toarray(), X_train_rel_app_text_bow.toarray()))\n",
    "X_test1 = np.hstack((X_test_abstract_bow.toarray(), X_test_rel_app_text_bow.toarray()))\n",
    "\n",
    "# Model 2: BOW abstract, BOW Related Application text, and Cosine Similarity\n",
    "# Combine TF-IDF features with cosine similarity\n",
    "X_train2 = np.hstack((X_train_abstract_bow.toarray(), X_train_rel_app_text_bow.toarray(), np.array(cosine_similarity_train_bow).reshape(-1, 1)))\n",
    "X_test2 = np.hstack((X_test_abstract_bow.toarray(), X_test_rel_app_text_bow.toarray(), np.array(cosine_similarity_test_bow).reshape(-1, 1)))\n",
    "\n",
    "# Model 3: BOW abstract, BOW Related Application text, and Fisher Cosine Similarity\n",
    "# I just choose Fisher Transformation Randomly because im an Economist, duh!\n",
    "X_train3 = np.hstack((X_train_abstract_bow.toarray(), X_train_rel_app_text_bow.toarray(), np.array(fisher_cosine_similarity_train_bow).reshape(-1, 1)))\n",
    "X_test3 = np.hstack((X_test_abstract_bow.toarray(), X_test_rel_app_text_bow.toarray(), np.array(fisher_cosine_similarity_test_bow).reshape(-1, 1)))\n",
    "\n",
    "# Model 4: TFIDF Abstract as the only feature\n",
    "X_train4 = X_train_abstract_tfidf.toarray()\n",
    "X_test4 = X_test_abstract_tfidf.toarray()\n",
    "\n",
    "# Model 5: Combine TF-IDF features from Abstract and Related Application Text\n",
    "X_train5 = np.hstack((X_train_abstract_tfidf.toarray(), X_train_rel_app_text_tfidf.toarray()))\n",
    "X_test5 = np.hstack((X_test_abstract_tfidf.toarray(), X_test_rel_app_text_tfidf.toarray()))\n",
    "\n",
    "# Model 6: TFIDF abstract, TFIDF Related Application text, and Cosine Similarity\n",
    "# Combine TF-IDF features with cosine similarity\n",
    "X_train6 = np.hstack((X_train_abstract_tfidf.toarray(), X_train_rel_app_text_tfidf.toarray(), np.array(cosine_similarity_train_tfidf).reshape(-1, 1)))\n",
    "X_test6 = np.hstack((X_test_abstract_tfidf.toarray(), X_test_rel_app_text_tfidf.toarray(), np.array(cosine_similarity_test_tfidf).reshape(-1, 1)))\n",
    "\n",
    "# Model 7: TFIDF abstract, TFIDF Related Application text, and Fisher Cosine Similarity\n",
    "# I just choose Fisher Transformation Randomly because im an Economist, duh!\n",
    "X_train7 = np.hstack((X_train_abstract_tfidf.toarray(), X_train_rel_app_text_tfidf.toarray(), np.array(fisher_cosine_similarity_train_tfidf).reshape(-1, 1)))\n",
    "X_test7 = np.hstack((X_test_abstract_tfidf.toarray(), X_test_rel_app_text_tfidf.toarray(), np.array(fisher_cosine_similarity_test_tfidf).reshape(-1, 1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T20:07:04.905718Z",
     "start_time": "2024-07-10T20:07:04.870391Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_logistic_regression_classifier(X_train, X_test, y_train, y_test):\n",
    "    # Define Logistic Regression Model and Parameter Grid\n",
    "    model = LogisticRegression()\n",
    "    param_grid = {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'solver': ['liblinear'],\n",
    "        'max_iter': [100, 200, 300]\n",
    "    }\n",
    "\n",
    "    # Perform GridSearchCV\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the Best Model and Evaluate\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Evaluate the Model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    return best_model, accuracy, report\n",
    "\n",
    "# Example usage\n",
    "# X_train, X_test, y_train, y_test should be defined with your actual data\n",
    "# best_model, accuracy, report = train_logistic_regression_classifier(X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T20:07:34.777398Z",
     "start_time": "2024-07-10T20:07:07.719609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best Parameters: {'C': 10, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Accuracy: 0.571\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.39      0.38       669\n",
      "           1       0.68      0.66      0.67      1331\n",
      "\n",
      "    accuracy                           0.57      2000\n",
      "   macro avg       0.53      0.53      0.53      2000\n",
      "weighted avg       0.58      0.57      0.57      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_modelL0, accuracyL0, reportL0 = train_logistic_regression_classifier(X_train0, X_test0, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T20:09:23.848540Z",
     "start_time": "2024-07-10T20:08:28.406130Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best Parameters: {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Accuracy: 0.578\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.39      0.38       669\n",
      "           1       0.69      0.67      0.68      1331\n",
      "\n",
      "    accuracy                           0.58      2000\n",
      "   macro avg       0.53      0.53      0.53      2000\n",
      "weighted avg       0.58      0.58      0.58      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_modelL1, accuracyL1, reportL1 = train_logistic_regression_classifier(X_train1, X_test1, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T20:15:51.341513Z",
     "start_time": "2024-07-10T20:14:59.340194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best Parameters: {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Accuracy: 0.5775\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.39      0.38       669\n",
      "           1       0.69      0.67      0.68      1331\n",
      "\n",
      "    accuracy                           0.58      2000\n",
      "   macro avg       0.53      0.53      0.53      2000\n",
      "weighted avg       0.58      0.58      0.58      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_modelL2, accuracyL2, reportL2 = train_logistic_regression_classifier(X_train2, X_test2, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T20:16:57.486254Z",
     "start_time": "2024-07-10T20:16:09.920448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best Parameters: {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Accuracy: 0.5775\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.39      0.38       669\n",
      "           1       0.69      0.67      0.68      1331\n",
      "\n",
      "    accuracy                           0.58      2000\n",
      "   macro avg       0.53      0.53      0.53      2000\n",
      "weighted avg       0.58      0.58      0.58      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_modelL3, accuracyL3, reportL3 = train_logistic_regression_classifier(X_train3, X_test3, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T20:17:32.321122Z",
     "start_time": "2024-07-10T20:17:02.967108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best Parameters: {'C': 100, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Accuracy: 0.6175\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.31      0.35       669\n",
      "           1       0.69      0.77      0.73      1331\n",
      "\n",
      "    accuracy                           0.62      2000\n",
      "   macro avg       0.55      0.54      0.54      2000\n",
      "weighted avg       0.60      0.62      0.60      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_modelL4, accuracyL4, reportL4 = train_logistic_regression_classifier(X_train4, X_test4, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T20:18:39.611763Z",
     "start_time": "2024-07-10T20:17:42.822931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best Parameters: {'C': 100, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Accuracy: 0.622\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.33      0.37       669\n",
      "           1       0.70      0.77      0.73      1331\n",
      "\n",
      "    accuracy                           0.62      2000\n",
      "   macro avg       0.56      0.55      0.55      2000\n",
      "weighted avg       0.60      0.62      0.61      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_modelL5, accuracyL5, reportL5 = train_logistic_regression_classifier(X_train5, X_test5, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T20:23:19.065922Z",
     "start_time": "2024-07-10T20:20:36.972554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best Parameters: {'C': 100, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Accuracy: 0.62\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.33      0.37       669\n",
      "           1       0.70      0.76      0.73      1331\n",
      "\n",
      "    accuracy                           0.62      2000\n",
      "   macro avg       0.56      0.55      0.55      2000\n",
      "weighted avg       0.60      0.62      0.61      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_modelL6, accuracyL6, reportL6 = train_logistic_regression_classifier(X_train6, X_test6, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T20:27:06.510651Z",
     "start_time": "2024-07-10T20:24:27.251632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best Parameters: {'C': 100, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Accuracy: 0.6205\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.33      0.37       669\n",
      "           1       0.70      0.76      0.73      1331\n",
      "\n",
      "    accuracy                           0.62      2000\n",
      "   macro avg       0.56      0.55      0.55      2000\n",
      "weighted avg       0.60      0.62      0.61      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_modelL7, accuracyL7, reportL7 = train_logistic_regression_classifier(X_train7, X_test7, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from scipy.stats import randint\n",
    "\n",
    "def train_random_forest_classifier(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # Define Random Forest Model and Parameter Grid\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    param_dist = {\n",
    "        'n_estimators': randint(10, 25, 50),\n",
    "        'max_depth': randint(5, 10, 15),\n",
    "        'min_samples_split': randint(2, 3, 6),\n",
    "        'min_samples_leaf': randint(1, 2, 3)\n",
    "    }\n",
    "\n",
    "    # Cross-validation strategy\n",
    "    cv_strategy = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Perform RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, \n",
    "                                       n_iter=50, cv=cv_strategy, scoring='accuracy', \n",
    "                                       verbose=2, n_jobs=-1, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the Best Model and Evaluate\n",
    "    best_model = random_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Evaluate the Model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    return best_model, accuracy, report\n",
    "\n",
    "# Example usage\n",
    "# best_model, accuracy, report = train_random_forest_classifier(X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best Parameters: {'max_depth': 24, 'min_samples_leaf': 4, 'min_samples_split': 8, 'n_estimators': 64}\n",
      "Accuracy: 0.602\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.44      0.42       669\n",
      "           1       0.71      0.68      0.70      1331\n",
      "\n",
      "    accuracy                           0.60      2000\n",
      "   macro avg       0.56      0.56      0.56      2000\n",
      "weighted avg       0.61      0.60      0.60      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model 0\n",
    "best_modelR0, accuracyR0, reportR0 = train_random_forest_classifier(X_train0, X_test0, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best Parameters: {'max_depth': 23, 'min_samples_leaf': 4, 'min_samples_split': 8, 'n_estimators': 72}\n",
      "Accuracy: 0.615\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.43      0.43       669\n",
      "           1       0.71      0.71      0.71      1331\n",
      "\n",
      "    accuracy                           0.61      2000\n",
      "   macro avg       0.57      0.57      0.57      2000\n",
      "weighted avg       0.62      0.61      0.62      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model 1\n",
    "best_modelR1, accuracyR1, reportR1 = train_random_forest_classifier(X_train1, X_test1, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best Parameters: {'max_depth': 23, 'min_samples_leaf': 4, 'min_samples_split': 8, 'n_estimators': 74}\n",
      "Accuracy: 0.6015\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.39      0.40       669\n",
      "           1       0.70      0.71      0.70      1331\n",
      "\n",
      "    accuracy                           0.60      2000\n",
      "   macro avg       0.55      0.55      0.55      2000\n",
      "weighted avg       0.60      0.60      0.60      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model 2\n",
    "best_modelR2, accuracyR2, reportR2 = train_random_forest_classifier(X_train2, X_test2, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best Parameters: {'max_depth': 23, 'min_samples_leaf': 4, 'min_samples_split': 8, 'n_estimators': 74}\n",
      "Accuracy: 0.6015\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.39      0.40       669\n",
      "           1       0.70      0.71      0.70      1331\n",
      "\n",
      "    accuracy                           0.60      2000\n",
      "   macro avg       0.55      0.55      0.55      2000\n",
      "weighted avg       0.60      0.60      0.60      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model 0\n",
    "best_modelR3, accuracyR3, reportR3 = train_random_forest_classifier(X_train3, X_test3, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best Parameters: {'max_depth': 23, 'min_samples_leaf': 4, 'min_samples_split': 8, 'n_estimators': 66}\n",
      "Accuracy: 0.614\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.35      0.38       669\n",
      "           1       0.70      0.75      0.72      1331\n",
      "\n",
      "    accuracy                           0.61      2000\n",
      "   macro avg       0.55      0.55      0.55      2000\n",
      "weighted avg       0.60      0.61      0.61      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_modelR4, accuracyR4, reportR4 = train_random_forest_classifier(X_train4, X_test4, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best Parameters: {'max_depth': 23, 'min_samples_leaf': 4, 'min_samples_split': 8, 'n_estimators': 73}\n",
      "Accuracy: 0.6205\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.35      0.38       669\n",
      "           1       0.70      0.76      0.73      1331\n",
      "\n",
      "    accuracy                           0.62      2000\n",
      "   macro avg       0.56      0.55      0.55      2000\n",
      "weighted avg       0.61      0.62      0.61      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_modelR5, accuracyR5, reportR5 = train_random_forest_classifier(X_train5, X_test5, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best Parameters: {'max_depth': 24, 'min_samples_leaf': 4, 'min_samples_split': 8, 'n_estimators': 61}\n",
      "Accuracy: 0.614\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.31      0.35       669\n",
      "           1       0.69      0.77      0.73      1331\n",
      "\n",
      "    accuracy                           0.61      2000\n",
      "   macro avg       0.54      0.54      0.54      2000\n",
      "weighted avg       0.59      0.61      0.60      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_modelR6, accuracyR6, reportR6 = train_random_forest_classifier(X_train6, X_test6, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best Parameters: {'max_depth': 24, 'min_samples_leaf': 4, 'min_samples_split': 8, 'n_estimators': 61}\n",
      "Accuracy: 0.614\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.31      0.35       669\n",
      "           1       0.69      0.77      0.73      1331\n",
      "\n",
      "    accuracy                           0.61      2000\n",
      "   macro avg       0.54      0.54      0.54      2000\n",
      "weighted avg       0.59      0.61      0.60      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_modelR7, accuracyR7, reportR7 = train_random_forest_classifier(X_train7, X_test7, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/anaconda3/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.11/site-packages (from xgboost) (1.11.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "def train_xgboost_classifier(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # Define XGBoost Model and Parameter Distribution\n",
    "    model = XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
    "    param_dist = {\n",
    "        'n_estimators': randint(45, 75),\n",
    "        'max_depth': randint(3, 10),\n",
    "        'learning_rate': uniform(0.01, 0.2),\n",
    "        'subsample': uniform(0.3, 0.6),\n",
    "        'colsample_bytree': uniform(0.3, 0.6),\n",
    "        'min_child_weight': randint(1, 10)\n",
    "    }\n",
    "\n",
    "    # Cross-validation strategy\n",
    "    cv_strategy = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Perform RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, \n",
    "                                       n_iter=50, cv=cv_strategy, scoring='accuracy', \n",
    "                                       verbose=2, n_jobs=-1, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the Best Model and Evaluate\n",
    "    best_model = random_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "     # Evaluate the Model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    return best_model, accuracy, report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 50 candidates, totalling 100 fits\n",
      "Best Parameters: {'colsample_bytree': 0.30795897669591993, 'learning_rate': 0.19844035113697056, 'max_depth': 8, 'min_child_weight': 2, 'n_estimators': 70, 'subsample': 0.4827682615040224}\n",
      "Accuracy: 0.5985\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.45      0.43       669\n",
      "           1       0.71      0.67      0.69      1331\n",
      "\n",
      "    accuracy                           0.60      2000\n",
      "   macro avg       0.56      0.56      0.56      2000\n",
      "weighted avg       0.61      0.60      0.60      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_modelX0, accuracyX0, reportX0 = train_xgboost_classifier(X_train0, X_test0, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 50 candidates, totalling 100 fits\n",
      "Best Parameters: {'colsample_bytree': 0.4218367348408616, 'learning_rate': 0.1985707141115962, 'max_depth': 9, 'min_child_weight': 3, 'n_estimators': 66, 'subsample': 0.8282807034091546}\n",
      "Accuracy: 0.5975\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.42      0.41       669\n",
      "           1       0.70      0.69      0.69      1331\n",
      "\n",
      "    accuracy                           0.60      2000\n",
      "   macro avg       0.55      0.55      0.55      2000\n",
      "weighted avg       0.60      0.60      0.60      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_modelX1, accuracyX1, reportX1 = train_xgboost_classifier(X_train1, X_test1, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 50 candidates, totalling 100 fits\n",
      "Best Parameters: {'colsample_bytree': 0.6642205486120107, 'learning_rate': 0.06519983640450867, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 69, 'subsample': 0.8921321619603104}\n",
      "Accuracy: 0.59\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.47      0.43       669\n",
      "           1       0.71      0.65      0.68      1331\n",
      "\n",
      "    accuracy                           0.59      2000\n",
      "   macro avg       0.56      0.56      0.56      2000\n",
      "weighted avg       0.61      0.59      0.60      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_modelX2, accuracyX2, reportX2 = train_xgboost_classifier(X_train2, X_test2, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 50 candidates, totalling 100 fits\n",
      "Best Parameters: {'colsample_bytree': 0.6642205486120107, 'learning_rate': 0.06519983640450867, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 69, 'subsample': 0.8921321619603104}\n",
      "Accuracy: 0.59\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.47      0.43       669\n",
      "           1       0.71      0.65      0.68      1331\n",
      "\n",
      "    accuracy                           0.59      2000\n",
      "   macro avg       0.56      0.56      0.56      2000\n",
      "weighted avg       0.61      0.59      0.60      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_modelX3, accuracyX3, reportX3 = train_xgboost_classifier(X_train3, X_test3, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 50 candidates, totalling 100 fits\n",
      "Best Parameters: {'colsample_bytree': 0.6642205486120107, 'learning_rate': 0.06519983640450867, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 69, 'subsample': 0.8921321619603104}\n",
      "Accuracy: 0.588\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.39      0.39       669\n",
      "           1       0.69      0.69      0.69      1331\n",
      "\n",
      "    accuracy                           0.59      2000\n",
      "   macro avg       0.54      0.54      0.54      2000\n",
      "weighted avg       0.59      0.59      0.59      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_modelX4, accuracyX4, reportX4 = train_xgboost_classifier(X_train4, X_test4, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 50 candidates, totalling 100 fits\n",
      "Best Parameters: {'colsample_bytree': 0.4218367348408616, 'learning_rate': 0.1985707141115962, 'max_depth': 9, 'min_child_weight': 3, 'n_estimators': 66, 'subsample': 0.8282807034091546}\n",
      "Accuracy: 0.6165\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.32      0.36       669\n",
      "           1       0.69      0.77      0.73      1331\n",
      "\n",
      "    accuracy                           0.62      2000\n",
      "   macro avg       0.55      0.54      0.54      2000\n",
      "weighted avg       0.60      0.62      0.60      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_modelX5, accuracyX5, reportX5 = train_xgboost_classifier(X_train5, X_test5, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 50 candidates, totalling 100 fits\n",
      "Best Parameters: {'colsample_bytree': 0.4218367348408616, 'learning_rate': 0.1985707141115962, 'max_depth': 9, 'min_child_weight': 3, 'n_estimators': 66, 'subsample': 0.8282807034091546}\n",
      "Accuracy: 0.619\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.33      0.37       669\n",
      "           1       0.69      0.76      0.73      1331\n",
      "\n",
      "    accuracy                           0.62      2000\n",
      "   macro avg       0.55      0.55      0.55      2000\n",
      "weighted avg       0.60      0.62      0.61      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_modelX6, accuracyX6, reportX6 = train_xgboost_classifier(X_train6, X_test6, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 50 candidates, totalling 100 fits\n",
      "Best Parameters: {'colsample_bytree': 0.4218367348408616, 'learning_rate': 0.1985707141115962, 'max_depth': 9, 'min_child_weight': 3, 'n_estimators': 66, 'subsample': 0.8282807034091546}\n",
      "Accuracy: 0.619\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.33      0.37       669\n",
      "           1       0.69      0.76      0.73      1331\n",
      "\n",
      "    accuracy                           0.62      2000\n",
      "   macro avg       0.55      0.55      0.55      2000\n",
      "weighted avg       0.60      0.62      0.61      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_modelX7, accuracyX7, reportX7 = train_xgboost_classifier(X_train7, X_test7, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Macine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def train_svm_classifier(X_train, X_test, y_train, y_test):\n",
    "    # Set up logging\n",
    "    \n",
    "    # Define SVM Model and Parameter Distribution\n",
    "    model = SVC(probability=True, random_state=42)\n",
    "    param_dist = {\n",
    "        'C': uniform(0.1, 10),\n",
    "        'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'degree': randint(2, 5)  # Used only if kernel='poly'\n",
    "    }\n",
    "\n",
    "    # Cross-validation strategy\n",
    "    cv_strategy = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Perform RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, \n",
    "                                       n_iter=50, cv=cv_strategy, scoring='accuracy', \n",
    "                                       verbose=2, n_jobs=-1, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the Best Model and Evaluate\n",
    "    best_model = random_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "   # Evaluate the Model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    return best_model, accuracy, report\n",
    "\n",
    "# Example usage\n",
    "# best_model, accuracy, report, confusion = train_svm_classifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 50 candidates, totalling 100 fits\n"
     ]
    }
   ],
   "source": [
    "best_modelS0, accuracyS0, reportS0 = train_svm_classifier(X_train0, X_test0, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_modelS1, accuracyS1, reportS1 = train_svm_classifier(X_train1, X_test1, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_modelS2, accuracyS2, reportS2 = train_svm_classifier(X_train2, X_test2, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_modelS3, accuracyS3, reportS3 = train_svm_classifier(X_train3, X_test3, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_modelS4, accuracyS4, reportS4 = train_svm_classifier(X_train4, X_test4, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_modelS5, accuracyS5, reportS5 = train_svm_classifier(X_train5, X_test5, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_modelS6, accuracyS6, reportS6 = train_svm_classifier(X_train6, X_test6, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_modelS7, accuracyS7, reportS7 = train_svm_classifier(X_train7, X_test7, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: TFIDF Vectorized Text and LDA Similarity Score with Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Similarity Score using LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune and Train LDA Model based on Unifed Corpus for both Abstract and Related Application Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T20:36:56.517044Z",
     "start_time": "2024-07-10T20:36:56.446454Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel, LdaModel\n",
    "\n",
    "def tune_lda_model(texts, topic_range, passes=15):\n",
    "    \"\"\"\n",
    "    Tune LDA model by selecting the number of topics with the best coherence score.\n",
    "\n",
    "    Parameters:\n",
    "    texts (list of list of str): List of tokenized documents\n",
    "    topic_range (list of int): List of topic numbers to try\n",
    "    passes (int): Number of passes through the corpus during training\n",
    "\n",
    "    Returns:\n",
    "    best_lda_model (gensim.models.LdaModel): Best LDA model\n",
    "    best_num_topics (int): Number of topics in the best model\n",
    "    best_coherence (float): Coherence score of the best model\n",
    "    \"\"\"\n",
    "    # Create a dictionary and corpus from the tokenized texts\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    \n",
    "    best_lda_model = None\n",
    "    best_num_topics = 0\n",
    "    best_coherence = -1\n",
    "    \n",
    "    # Iterate over the topic range to find the best number of topics\n",
    "    for num_topics in topic_range:\n",
    "        # Train LDA model with the current number of topics\n",
    "        lda_model = LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=passes)\n",
    "        \n",
    "        # Calculate coherence score for the model\n",
    "        coherence_model = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_score = coherence_model.get_coherence()\n",
    "        \n",
    "        # Update the best model if the current model has a better coherence score\n",
    "        if coherence_score > best_coherence:\n",
    "            best_coherence = coherence_score\n",
    "            best_num_topics = num_topics\n",
    "            best_lda_model = lda_model\n",
    "            \n",
    "    return best_lda_model, best_num_topics, best_coherence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T20:37:03.718451Z",
     "start_time": "2024-07-10T20:37:03.705859Z"
    }
   },
   "outputs": [],
   "source": [
    "# This is different from the previously implemented preprocess function,\n",
    "# This one does not join the tokens after setemming\n",
    "def preprocess_text1(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove punctuation and convert to lowercase\n",
    "    tokens = [word.lower() for word in tokens if word.isalpha()]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    \n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T20:37:29.037664Z",
     "start_time": "2024-07-10T20:37:10.712242Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Apply preprocessing to application_abstract column\n",
    "df['application_abstract'] = df['application_abstract'].apply(preprocess_text1)\n",
    "\n",
    "# Apply preprocessing to rel_app_text column\n",
    "df['rel_app_text'] = df['rel_app_text'].apply(preprocess_text1)\n",
    "\n",
    "# Combine the abstract and related application text for vocabulary fitting\n",
    "combined_text = df['application_abstract'] + df['rel_app_text']\n",
    "\n",
    "# Tokenize each document in combined_text\n",
    "tokenized_combined_text = combined_text.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T20:59:40.291883Z",
     "start_time": "2024-07-10T20:43:21.255006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   0.4s\n",
      "[CV] END .C=0.01, max_iter=200, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END .C=0.01, max_iter=300, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ..C=0.1, max_iter=200, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ..C=0.1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END ..C=0.1, max_iter=300, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l1, solver=liblinear; total time=   0.7s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ....C=1, max_iter=300, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END ....C=1, max_iter=300, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ...C=10, max_iter=300, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ..C=100, max_iter=100, penalty=l1, solver=liblinear; total time=   0.9s\n",
      "[CV] END ..C=100, max_iter=200, penalty=l1, solver=liblinear; total time=   0.8s\n",
      "[CV] END ..C=100, max_iter=200, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END ..C=100, max_iter=300, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   1.6s\n",
      "[CV] END .C=0.01, max_iter=200, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END .C=0.01, max_iter=300, penalty=l1, solver=liblinear; total time=   0.7s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END ..C=0.1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ..C=0.1, max_iter=300, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END ....C=1, max_iter=300, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l1, solver=liblinear; total time=   0.9s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l1, solver=liblinear; total time=   0.9s\n",
      "[CV] END ...C=10, max_iter=300, penalty=l1, solver=liblinear; total time=   0.8s\n",
      "[CV] END ..C=100, max_iter=100, penalty=l1, solver=liblinear; total time=   1.1s\n",
      "[CV] END ..C=100, max_iter=200, penalty=l1, solver=liblinear; total time=   1.0s\n",
      "[CV] END ..C=100, max_iter=300, penalty=l1, solver=liblinear; total time=   1.2s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   1.5s\n",
      "[CV] END .C=0.01, max_iter=200, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END .C=0.01, max_iter=300, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END .C=0.01, max_iter=300, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END ..C=0.1, max_iter=200, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ..C=0.1, max_iter=300, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ..C=0.1, max_iter=300, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.4s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ....C=1, max_iter=300, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l1, solver=liblinear; total time=   0.9s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l1, solver=liblinear; total time=   0.9s\n",
      "[CV] END ...C=10, max_iter=300, penalty=l1, solver=liblinear; total time=   0.9s\n",
      "[CV] END ...C=10, max_iter=300, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END ..C=100, max_iter=100, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END ..C=100, max_iter=200, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END ..C=100, max_iter=300, penalty=l1, solver=liblinear; total time=   1.2s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END .C=0.01, max_iter=200, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END .C=0.01, max_iter=300, penalty=l1, solver=liblinear; total time=   0.7s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END ..C=0.1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END ..C=0.1, max_iter=300, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END ....C=1, max_iter=300, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END ....C=1, max_iter=300, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ...C=10, max_iter=300, penalty=l1, solver=liblinear; total time=   0.8s\n",
      "[CV] END ..C=100, max_iter=100, penalty=l1, solver=liblinear; total time=   0.9s\n",
      "[CV] END ..C=100, max_iter=100, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ..C=100, max_iter=200, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END ..C=100, max_iter=300, penalty=l1, solver=liblinear; total time=   1.0s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   0.4s\n",
      "[CV] END .C=0.01, max_iter=200, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END .C=0.01, max_iter=300, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ..C=0.1, max_iter=200, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ..C=0.1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END ..C=0.1, max_iter=300, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END ....C=1, max_iter=300, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END ...C=10, max_iter=300, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ...C=10, max_iter=300, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END ..C=100, max_iter=100, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ..C=100, max_iter=200, penalty=l1, solver=liblinear; total time=   1.0s\n",
      "[CV] END ..C=100, max_iter=200, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ..C=100, max_iter=300, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   1.5s\n",
      "[CV] END .C=0.01, max_iter=200, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END .C=0.01, max_iter=300, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END .C=0.01, max_iter=300, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END ..C=0.1, max_iter=200, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ..C=0.1, max_iter=300, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END ..C=0.1, max_iter=300, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ....C=1, max_iter=300, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l1, solver=liblinear; total time=   1.0s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l1, solver=liblinear; total time=   0.9s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ...C=10, max_iter=300, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ..C=100, max_iter=100, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END ..C=100, max_iter=100, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ..C=100, max_iter=200, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END ..C=100, max_iter=300, penalty=l1, solver=liblinear; total time=   1.1s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   1.6s\n",
      "[CV] END .C=0.01, max_iter=200, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END .C=0.01, max_iter=200, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END .C=0.01, max_iter=300, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END ..C=0.1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END ..C=0.1, max_iter=300, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l1, solver=liblinear; total time=   0.7s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l1, solver=liblinear; total time=   0.7s\n",
      "[CV] END ....C=1, max_iter=300, penalty=l1, solver=liblinear; total time=   0.7s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l1, solver=liblinear; total time=   1.0s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l1, solver=liblinear; total time=   1.0s\n",
      "[CV] END ...C=10, max_iter=300, penalty=l1, solver=liblinear; total time=   0.8s\n",
      "[CV] END ..C=100, max_iter=100, penalty=l1, solver=liblinear; total time=   1.1s\n",
      "[CV] END ..C=100, max_iter=200, penalty=l1, solver=liblinear; total time=   1.0s\n",
      "[CV] END ..C=100, max_iter=300, penalty=l1, solver=liblinear; total time=   1.0s\n",
      "[CV] END ..C=100, max_iter=300, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END .C=0.01, max_iter=200, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END .C=0.01, max_iter=200, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END .C=0.01, max_iter=300, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END ..C=0.1, max_iter=200, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END ..C=0.1, max_iter=300, penalty=l1, solver=liblinear; total time=   0.7s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ....C=1, max_iter=300, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l1, solver=liblinear; total time=   0.9s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l1, solver=liblinear; total time=   1.0s\n",
      "[CV] END ...C=10, max_iter=300, penalty=l1, solver=liblinear; total time=   0.9s\n",
      "[CV] END ..C=100, max_iter=100, penalty=l1, solver=liblinear; total time=   1.1s\n",
      "[CV] END ..C=100, max_iter=200, penalty=l1, solver=liblinear; total time=   1.1s\n",
      "[CV] END ..C=100, max_iter=300, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END ..C=100, max_iter=300, penalty=l2, solver=liblinear; total time=   0.4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<gensim.models.ldamodel.LdaModel at 0x3349f2310>, 5, 0.5511164061267257)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_unified_corpus = tokenized_combined_text\n",
    "topic_range = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "passes = 20\n",
    "\n",
    "tune_lda_model(tokenized_unified_corpus, topic_range, passes=passes) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a function that extract the LDA topic distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T21:04:21.849946Z",
     "start_time": "2024-07-10T21:04:21.796064Z"
    }
   },
   "outputs": [],
   "source": [
    "def lda_topic_distribution(documents1, documents2, num_topics, passes=20):\n",
    "    \"\"\"\n",
    "    Generate LDA topic distributions for two sets of documents using a unified dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    documents1 (list of str): List of documents for the first text variable (application_abstact)\n",
    "    documents2 (list of str): List of documents for the second text variable (rel_app_text)\n",
    "    num_topics (int): Number of topics for the LDA model\n",
    "    passes (int): Number of passes through the corpus during training\n",
    "\n",
    "    Returns:\n",
    "    lda_model (gensim.models.LdaModel): LDA model\n",
    "    dictionary (gensim.corpora.Dictionary): Dictionary of the combined corpus\n",
    "    corpus1 (list of list of (int, int)): Corpus for documents1 in bag-of-words format\n",
    "    corpus2 (list of list of (int, int)): Corpus for documents2 in bag-of-words format\n",
    "    doc_topic_matrix1 (numpy.ndarray): Dense matrix of topic distributions for documents1\n",
    "    doc_topic_matrix2 (numpy.ndarray): Dense matrix of topic distributions for documents2\n",
    "    \"\"\"\n",
    "    # Preprocess documents\n",
    "    documents1 = [preprocess_text1(doc) for doc in documents1]\n",
    "    documents2 = [preprocess_text1(doc) for doc in documents2]\n",
    "\n",
    "    # Combine the documents for creating a unified dictionary\n",
    "    unified_dictionary = documents1 + documents2\n",
    "\n",
    "    # Create a dictionary and corpus from the combined texts\n",
    "    dictionary = corpora.Dictionary(unified_dictionary)\n",
    "    corpus_combined = [dictionary.doc2bow(text) for text in unified_dictionary]\n",
    "\n",
    "    # Transform each document into the bag-of-words format using the unified dictionary\n",
    "    corpus1 = [dictionary.doc2bow(text) for text in documents1]\n",
    "    corpus2 = [dictionary.doc2bow(text) for text in documents2]\n",
    "\n",
    "    # Train LDA model with the specified number of topics\n",
    "    lda_model = LdaModel(corpus_combined, num_topics=num_topics, id2word=dictionary, passes=passes)\n",
    "\n",
    "    # Get topic distributions for each document\n",
    "    doc_topics1 = [lda_model.get_document_topics(bow, minimum_probability=0) for bow in corpus1]\n",
    "    doc_topics2 = [lda_model.get_document_topics(bow, minimum_probability=0) for bow in corpus2]\n",
    "\n",
    "    # Convert topic distributions to dense matrices\n",
    "    num_terms = num_topics\n",
    "    doc_topic_matrix1 = np.zeros((len(documents1), num_terms))\n",
    "    for i, doc in enumerate(doc_topics1):\n",
    "        for topic_num, prob in doc:\n",
    "            doc_topic_matrix1[i, topic_num] = prob\n",
    "\n",
    "    doc_topic_matrix2 = np.zeros((len(documents2), num_terms))\n",
    "    for i, doc in enumerate(doc_topics2):\n",
    "        for topic_num, prob in doc:\n",
    "            doc_topic_matrix2[i, topic_num] = prob\n",
    "\n",
    "    return lda_model, dictionary, corpus1, corpus2, doc_topic_matrix1, doc_topic_matrix2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T21:06:39.115746Z",
     "start_time": "2024-07-10T21:05:04.829331Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set - Abstract Topic Matrix 1:\n",
      " [[0.00233762 0.00233482 0.04670783 0.94627637 0.00234336]\n",
      " [0.11893915 0.34684557 0.00322854 0.52767819 0.00330857]\n",
      " [0.33140531 0.00220492 0.00214086 0.24563509 0.41861382]\n",
      " ...\n",
      " [0.00258584 0.19112583 0.00260732 0.62884307 0.17483792]\n",
      " [0.0033356  0.08346131 0.00332106 0.83913767 0.07074437]\n",
      " [0.74918604 0.00812212 0.00806491 0.2263454  0.00828149]]\n",
      "Training Set - Abstract Topic Matrix 2:\n",
      " [[0.00714521 0.00715331 0.97140872 0.00714733 0.00714542]\n",
      " [0.0250001  0.02501273 0.89995837 0.02500156 0.02502721]\n",
      " [0.01055222 0.01053963 0.9578371  0.01053708 0.010534  ]\n",
      " ...\n",
      " [0.01429315 0.01429741 0.94283158 0.01428931 0.01428854]\n",
      " [0.00870284 0.00871434 0.96518445 0.00869831 0.0087001 ]\n",
      " [0.00833515 0.00833537 0.96665937 0.00833455 0.00833558]]\n",
      "Testing Set - Related Document Topic Matrix 1:\n",
      " [[0.82592517 0.00248983 0.13519804 0.00243863 0.03394832]\n",
      " [0.16339615 0.40428215 0.0059554  0.42043769 0.00592861]\n",
      " [0.86302471 0.00217689 0.00217067 0.13046749 0.00216024]\n",
      " ...\n",
      " [0.00554103 0.00557378 0.97761643 0.00576485 0.00550388]\n",
      " [0.97911304 0.00521619 0.00510463 0.005536   0.00503015]\n",
      " [0.36007139 0.16585656 0.47015104 0.00198064 0.0019404 ]]\n",
      "Testing Set - Related Document Topic Matrix 2:\n",
      " [[0.01177213 0.01177191 0.01176962 0.0118121  0.95287418]\n",
      " [0.01333853 0.01333663 0.01333558 0.01334623 0.94664299]\n",
      " [0.01112976 0.01112227 0.01114773 0.0111173  0.95548296]\n",
      " ...\n",
      " [0.01000368 0.01000252 0.01000193 0.01000802 0.95998383]\n",
      " [0.01000677 0.01000632 0.01000451 0.01003566 0.95994675]\n",
      " [0.0117729  0.01177257 0.0117692  0.01181042 0.95287484]]\n"
     ]
    }
   ],
   "source": [
    "# Call the lda_topic_distribution function on the train and \n",
    "X_train_abstract = X_train['application_abstract']\n",
    "X_test_abstract = X_test['application_abstract']\n",
    "X_train_rel_app_text = X_train['rel_app_text']\n",
    "X_test_rel_app_text = X_test['rel_app_text']\n",
    "\n",
    "# Define the number of topics and passes\n",
    "num_topics = 5\n",
    "passes = 20\n",
    "\n",
    "# Call lda_topic_distribution for training set\n",
    "lda_model_train, dictionary_train, corpus1_train, corpus2_train, train_abstract_topic_matrix1, train_rel_app_text_topic_matrix2 = lda_topic_distribution(X_train_abstract, X_train_rel_app_text, num_topics, passes)\n",
    "\n",
    "# Save the topic matrices for the training set\n",
    "np.save('train_abstract_topic_matrix1.npy',train_abstract_topic_matrix1 )\n",
    "np.save('train_rel_app_text_topic_matrix2.npy', train_rel_app_text_topic_matrix2)\n",
    "\n",
    "# Call lda_topic_distribution for testing set\n",
    "lda_model_test, dictionary_test, corpus1_test, corpus2_test, test_abstract_topic_matrix1, test_rel_app_texttopic_matrix2 = lda_topic_distribution(X_test_abstract, X_test_rel_app_text, num_topics, passes)\n",
    "\n",
    "# Save the topic matrices for the testing set\n",
    "np.save('test_abstract_topic_matrix1.npy', test_abstract_topic_matrix1)\n",
    "np.save('test_rel_app_texttopic_matrix2.npy', test_rel_app_texttopic_matrix2)\n",
    "\n",
    "print(\"Training Set - Abstract Topic Matrix 1:\\n\", train_abstract_topic_matrix1 )\n",
    "print(\"Training Set - Abstract Topic Matrix 2:\\n\", train_rel_app_text_topic_matrix2)\n",
    "print(\"Testing Set - Related Document Topic Matrix 1:\\n\", test_abstract_topic_matrix1)\n",
    "print(\"Testing Set - Related Document Topic Matrix 2:\\n\", test_rel_app_texttopic_matrix2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T21:08:01.753400Z",
     "start_time": "2024-07-10T21:08:00.495007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1253    0.056696\n",
      "3725    0.048050\n",
      "116     0.022322\n",
      "1199    0.014405\n",
      "1523    0.014921\n",
      "Name: lda_cosine_similarity, dtype: float64\n",
      "3431    0.054762\n",
      "2042    0.032899\n",
      "79      0.015785\n",
      "4663    0.009433\n",
      "3640    0.999941\n",
      "Name: lda_cosine_similarity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Calculate cosine similarity for training data\n",
    "lda_cosine_similarity_train = [\n",
    "    cosine_similarity(\n",
    "        train_abstract_topic_matrix1[i].reshape(1, -1),\n",
    "        train_rel_app_text_topic_matrix2[i].reshape(1, -1)\n",
    "    )[0, 0]\n",
    "    for i in range(train_abstract_topic_matrix1.shape[0])\n",
    "]\n",
    "\n",
    "# Calculate cosine similarity for test data\n",
    "lda_cosine_similarity_test = [\n",
    "    cosine_similarity(\n",
    "        test_abstract_topic_matrix1[i].reshape(1, -1),\n",
    "        test_rel_app_texttopic_matrix2[i].reshape(1, -1)\n",
    "    )[0, 0]\n",
    "    for i in range(test_abstract_topic_matrix1.shape[0])\n",
    "]\n",
    "\n",
    "# Add cosine similarity to the dataframes\n",
    "X_train['lda_cosine_similarity'] = lda_cosine_similarity_train\n",
    "X_test['lda_cosine_similarity'] = lda_cosine_similarity_test\n",
    "\n",
    "print(X_train['lda_cosine_similarity'].head())\n",
    "print(X_test['lda_cosine_similarity'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, We run a Baseline Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T22:43:25.716768Z",
     "start_time": "2024-07-10T22:42:58.029940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best Parameters: {'C': 100, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Accuracy: 0.619\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.32      0.36       669\n",
      "           1       0.69      0.77      0.73      1331\n",
      "\n",
      "    accuracy                           0.62      2000\n",
      "   macro avg       0.55      0.54      0.54      2000\n",
      "weighted avg       0.60      0.62      0.60      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combine TF-IDF features with lda cosine similarity\n",
    "X_train_combined_lda = np.hstack((X_train_abstract_tfidf.toarray(), np.array(lda_cosine_similarity_train).reshape(-1, 1)))\n",
    "X_test_combined_lda = np.hstack((X_test_abstract_tfidf.toarray(), np.array(lda_cosine_similarity_test).reshape(-1, 1)))\n",
    "\n",
    "# Step 5: Define the model and parameter grid for GridSearch\n",
    "model = LogisticRegression()\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear'],\n",
    "    'max_iter': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# Step 6: Perform GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train_combined_lda, y_train)\n",
    "\n",
    "# Step 7: Get the best model and evaluate\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_combined_lda)\n",
    "\n",
    "# Step 8: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
